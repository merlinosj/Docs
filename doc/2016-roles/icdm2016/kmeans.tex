\section{Iterative algorithm}
\label{sec:kmeans}

Proposition~\ref{proposition:np-fixed} states that if we fix centroids, then
the problem remains intractable, even worse it cannot be approximated. This is
a blowback to the standard iterative heuristic, where one set of parameters is
fixed while the other set of parameters is optimized.

However, if we were to fix the \emph{profiles}, then the optimization task
transforms into a traditional clustering problem. Once, we have discovered a
role assignment, we can recompute the profiles, and repeat until we converge
into a local minimum. This is exactly what we do in Algorithm~\ref{alg:iterative}.

\begin{algorithm}
\caption{$\algiterative(G, k)$, an iterative method for computing roles.
\algcluster is a standard clustering method.}
\label{alg:iterative}
$r_0 \define \algcluster(\dg{\cdot}, k)$ \;
$i \define 0$\;
\While {cost decreases} {
	$r_{i + 1} \define \algcluster(\prof{\cdot, r_i}, k)$ \;
	$i \define i + 1$\;
}
\end{algorithm}

We still have the task to solve the clustering problem. Here, we resort to a
standard $k$-means clustering algorithm. We will denote the resulting algorithm
by $\algiterative$.

Note that computing profiles from the role assignment can be done efficiently
in $\bigO{\max\{kn, m\}}$ time, where $n$ is the number of vertices and $m$ is
the number of edges. The $\bigO{kn}$ time is needed to initialize $n$ vectors of length $k$.
If the clustering algorithm allows to have sparse representation
of the profiles, the processing time can be further reduced to $\bigO{m}$ time.
Thus, the computational bottleneck is the clustering algorithm, as
well as how many iterations we typically need to converge.
